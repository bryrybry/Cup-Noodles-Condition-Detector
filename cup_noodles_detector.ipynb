{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88efb84d",
   "metadata": {},
   "source": [
    "### ‚¨áÔ∏è Imports & Configs\n",
    "**‚ö†Ô∏è IMPORTANT: Run this before anything else**\n",
    "\n",
    "*(You can change the numbers within CONFIG)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4f0b6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image, ImageOps\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import datetime\n",
    "import threading\n",
    "\n",
    "CONFIG = {\n",
    "    'IMG_SIZE': (224, 224), # Max: 299x299 for InceptionV3\n",
    "    'BATCH_SIZE': 24, # ~24 for Laptop, ~48 for PC\n",
    "    'EPOCHS': 3, # I tested 5 is seems to be quite gd, but increase if you're willing to train for longer\n",
    "    'DISTRIBUTE_CLASS_WEIGHTS': True # Default: True, will alleviate uneven class image distribution\n",
    "}\n",
    "\n",
    "data_dir = './data'\n",
    "class_names = ['Finished', 'Opened', 'Sealed']\n",
    "\n",
    "print(\"‚úÖ Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ed850f",
   "metadata": {},
   "source": [
    "# 1. Model Training\n",
    "**Trains the model then saves it as a .keras model file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c4908a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checking dataset...\n",
      "Dataset Balance:\n",
      "{'Finished': 548, 'Opened': 448, 'Sealed': 675}\n",
      "Ratios: {'Finished': '32.8%', 'Opened': '26.8%', 'Sealed': '40.4%'}\n",
      "\n",
      "üìä Loading data...\n",
      "Found 1338 images belonging to 3 classes.\n",
      "Found 1463 images belonging to 3 classes.\n",
      "Found 208 images belonging to 3 classes.\n",
      "\n",
      "üèóÔ∏è Building model...\n",
      "\n",
      "‚öñÔ∏è Computing class weights...\n",
      "Class weights: {0: np.float64(1.0159453302961277), 1: np.float64(1.2423398328690807), 2: np.float64(0.825925925925926)}\n",
      "\n",
      "üöÄ Training...\n",
      "Epoch 1/3\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6157 - loss: 1.2759"
     ]
    }
   ],
   "source": [
    "def check_dataset_balance(data_dir):\n",
    "    \"\"\"Verify class distribution before training.\"\"\"\n",
    "    counts = {}\n",
    "    for class_dir in sorted(os.listdir(data_dir)):  # Consistent order\n",
    "        class_path = os.path.join(data_dir, class_dir)\n",
    "        if os.path.isdir(class_path):\n",
    "            counts[class_dir] = len([f for f in os.listdir(class_path) \n",
    "                                   if f.lower().endswith(('.jpg', '.png', '.jpeg'))])\n",
    "    \n",
    "    total = sum(counts.values())\n",
    "    print(\"Dataset Balance:\")\n",
    "    print(counts)\n",
    "    print(\"Ratios:\", {k: f\"{v/total*100:.1f}%\" for k,v in counts.items()})\n",
    "    return counts\n",
    "\n",
    "def get_image_generators(data_dir, img_size, batch_size):\n",
    "    \"\"\"Simplified 80/10/10 split - more reliable than validation_split trick.\"\"\"\n",
    "    seed = 42\n",
    "    \n",
    "    # Train: augmentation\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        validation_split=0.2  # 80/20 split\n",
    "    )\n",
    "    \n",
    "    train_gen = train_datagen.flow_from_directory(\n",
    "        data_dir, target_size=img_size, batch_size=batch_size,\n",
    "        class_mode='categorical', subset='training', seed=seed\n",
    "    )\n",
    "    \n",
    "    # Val/Test: no augmentation\n",
    "    val_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.125)  # 10% val, 10% test\n",
    "    \n",
    "    val_gen = val_datagen.flow_from_directory(\n",
    "        data_dir, target_size=img_size, batch_size=batch_size,\n",
    "        class_mode='categorical', subset='training', seed=seed, shuffle=False\n",
    "    )\n",
    "    \n",
    "    test_gen = val_datagen.flow_from_directory(\n",
    "        data_dir, target_size=img_size, batch_size=batch_size,\n",
    "        class_mode='categorical', subset='validation', seed=seed, shuffle=False\n",
    "    )\n",
    "    \n",
    "    return train_gen, val_gen, test_gen\n",
    "\n",
    "def build_improved_model(img_shape, num_classes):\n",
    "    \"\"\"Better architecture: GlobalAvgPool2D + more layers.\"\"\"\n",
    "    base_model = InceptionV3(input_shape=(*img_shape, 3), include_top=False, weights='imagenet')\n",
    "    \n",
    "    # Freeze base\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Better head (no Flatten = less params)\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "# MAIN TRAINING PIPELINE\n",
    "print(\"üîç Checking dataset...\")\n",
    "check_dataset_balance(data_dir)\n",
    "\n",
    "print(\"\\nüìä Loading data...\")\n",
    "train_gen, val_gen, test_gen = get_image_generators(\n",
    "    data_dir, CONFIG['IMG_SIZE'], CONFIG['BATCH_SIZE']\n",
    ")\n",
    "\n",
    "print(\"\\nüèóÔ∏è Building model...\")\n",
    "model = build_improved_model(CONFIG['IMG_SIZE'], len(class_names))\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "# model.summary()\n",
    "\n",
    "print(\"\\n‚öñÔ∏è Computing class weights...\")\n",
    "class_weights = compute_class_weight(\n",
    "    'balanced', classes=np.unique(train_gen.classes), y=train_gen.classes\n",
    ")\n",
    "class_indices = train_gen.class_indices  # {'Finished': 0, 'Opened': 1, 'Sealed': 2}\n",
    "class_weight_dict = {class_indices[class_name]: weight \n",
    "                     for class_name, weight in zip(class_indices.keys(), class_weights)}\n",
    "print(\"Class weights:\", class_weight_dict)\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=5, restore_best_weights=True, monitor='val_accuracy'),\n",
    "    ReduceLROnPlateau(factor=0.2, patience=3, min_lr=1e-7)\n",
    "]\n",
    "\n",
    "print(\"\\nüöÄ Training...\")\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    epochs=CONFIG['EPOCHS'],\n",
    "    validation_data=val_gen,\n",
    "    class_weight=class_weight_dict,  # Handles your imbalance!\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Test accuracy:\", model.evaluate(test_gen)[1])\n",
    "\n",
    "# Save with timestamp\n",
    "timestamp = datetime.datetime.now().strftime(\"%b%d_%H%M\")\n",
    "model.save(f'./models/cup_noodle_classifier_{timestamp}.keras')\n",
    "print(f\"üíæ Saved: cup_noodle_classifier_{timestamp}.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cb305a",
   "metadata": {},
   "source": [
    "## ======================================\n",
    "# 2. Trying the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63f7e9e",
   "metadata": {},
   "source": [
    "### üîÉ Load a .keras model\n",
    "Loading a model is necessary if the above code to train a new model was not executed.\n",
    "(Skip this if model was recently trained above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a8dfae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model Loaded: cup_noodle_classifier_20260129_144829.keras\n"
     ]
    }
   ],
   "source": [
    "folder = \"./models/\"\n",
    "files = os.listdir(folder)\n",
    "\n",
    "# sort by last added time\n",
    "if not files: raise FileNotFoundError(\"No models found!\")\n",
    "files_sorted = sorted(files, key=lambda f: os.path.getmtime(os.path.join(folder, f)))\n",
    "last_added_filename = files_sorted[-1]\n",
    "\n",
    "while True:\n",
    "    input_filename = input(\n",
    "        f\"Enter model to load (Latest: {last_added_filename.replace('.keras', '')}): \"\n",
    "    ).strip()\n",
    "\n",
    "    if input_filename == \"\":\n",
    "        model_filename = last_added_filename\n",
    "        break\n",
    "\n",
    "    model_filename = f\"{input_filename.replace('.keras', '')}.keras\"\n",
    "    full_path = os.path.join(folder, model_filename)\n",
    "\n",
    "    if os.path.exists(full_path):\n",
    "        break\n",
    "    else:\n",
    "        print(\"‚ùå Model not found. Please try again.\")\n",
    "\n",
    "model = tf.keras.models.load_model(f'./models/{model_filename}')\n",
    "\n",
    "print(\"‚úÖ Model Loaded:\", model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f89a33",
   "metadata": {},
   "source": [
    "### new version of code below, yet to test tho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aa04e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import os\n",
    "\n",
    "folder = \"./models/\"\n",
    "files = [f for f in os.listdir(folder) if f.endswith('.keras')]\n",
    "\n",
    "if not files:\n",
    "    raise FileNotFoundError(\"No .keras models found in ./models/!\")\n",
    "\n",
    "# Sort by last modified (newest first)\n",
    "files_sorted = sorted(files, key=lambda f: os.path.getmtime(os.path.join(folder, f)), reverse=True)\n",
    "latest_model = files_sorted[0]\n",
    "\n",
    "print(f\"üìÅ Found {len(files)} models. Latest: {latest_model}\")\n",
    "\n",
    "# File dialog - filter .keras files only\n",
    "root = tk.Tk()\n",
    "root.withdraw()  # Hide main window\n",
    "\n",
    "model_paths = filedialog.askopenfilenames(\n",
    "    title=\"Select model file (.keras)\",\n",
    "    initialdir=folder,\n",
    "    filetypes=[(\"Keras models\", \"*.keras\"), (\"All files\", \"*.*\")]\n",
    ")\n",
    "\n",
    "root.destroy()\n",
    "\n",
    "if not model_paths:\n",
    "    print(\"‚ùå No model selected. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "# Use first selected (or only) model\n",
    "model_filename = os.path.basename(model_paths[0])\n",
    "full_path = model_paths[0]\n",
    "\n",
    "print(f\"‚úÖ Loading: {model_filename}\")\n",
    "model = tf.keras.models.load_model(full_path)\n",
    "print(\"üöÄ Model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c72f5ac",
   "metadata": {},
   "source": [
    "### Part 2: Inference using Camera Stream üì∑ \n",
    "(Please view the cell under this one to terminate the camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a6ca96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera Started!\n"
     ]
    }
   ],
   "source": [
    "def import_and_predict(image_data):\n",
    "    image = ImageOps.fit(image_data, CONFIG['IMG_SIZE'], Image.Resampling.LANCZOS)\n",
    "    image = image.convert('RGB')\n",
    "    image = np.asarray(image)\n",
    "    image = (image.astype(np.float32) / 255.0)\n",
    "    img_reshape = image[np.newaxis,...]\n",
    "    prediction = model.predict(img_reshape, verbose=0)\n",
    "    return prediction\n",
    "\n",
    "stop_flag = False\n",
    "\n",
    "def camera_loop():\n",
    "    global stop_flag\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        cap.open()\n",
    "        \n",
    "    print(\"Camera Started!\")\n",
    "\n",
    "    while not stop_flag:\n",
    "        ret, original = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        image = Image.fromarray(cv2.cvtColor(original, cv2.COLOR_BGR2RGB))\n",
    "        prediction = import_and_predict(image)\n",
    "\n",
    "        idx = np.argmax(prediction)\n",
    "        confidence = prediction[0][idx] \n",
    "\n",
    "        predict = f\"It is a {class_names[idx]}! ({confidence:.2f})\"\n",
    "\n",
    "        cv2.putText(original, predict, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "        cv2.imshow(\"Cup Noodles Detector\", original)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            stop_flag = True\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# start the camera in a separate thread\n",
    "camera_thread = threading.Thread(target=camera_loop)\n",
    "camera_thread.start()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0569d8e4",
   "metadata": {},
   "source": [
    "‚ùå Run to terminate the camera! üëá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87c4efcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Killed the Camera!\n"
     ]
    }
   ],
   "source": [
    "stop_flag = True\n",
    "camera_thread.join()\n",
    "print(\"Killed the Camera!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
