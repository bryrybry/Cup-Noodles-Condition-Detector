{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0870da33",
   "metadata": {},
   "source": [
    "- Datasets Preparation (using phone/camera to capture images) 10\n",
    "- Dataset Expansion (splitting data into Training, Validation, and Test sets) 10\n",
    "- Model Building, Training, and Comparisons 25\n",
    "- Data Visualization (using Matplotlib for graphs such as loss vs. epochs, accuracy vs. epochs) 10\n",
    "- Real-Time Image Recognition (live testing on the spot) 10\n",
    "- Video Presentation (10-15 minutes per group) 15\n",
    "- Reflection and Q&A 5\n",
    "- Submission of Work 5\n",
    "- Extra \"WOW\" Factor (e.g., innovative approach or additional features) 10\n",
    "- Grand Total 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88efb84d",
   "metadata": {},
   "source": [
    "### ‚¨áÔ∏è Imports & Configs\n",
    "**‚ö†Ô∏è IMPORTANT: Run this before anything else**\n",
    "\n",
    "*(You can change the hyperparameters within HYPER_PARAMS dict)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f0b6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorflow opencv-python pillow matplotlib scikit-learn\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageOps\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import datetime\n",
    "import threading\n",
    "\n",
    "HYPER_PARAMS = {\n",
    "    'IMG_SIZE': (299, 299), # Max: 299x299 for InceptionV3\n",
    "    'BATCH_SIZE': 48, # ~24 for Laptop, ~48 for PC\n",
    "    'EPOCHS': 1, # 12-18 is when it will early stop on its own\n",
    "    'DISTRIBUTE_CLASS_WEIGHTS': True # Default: True, will alleviate uneven class image distribution\n",
    "}\n",
    "\n",
    "data_dir = './data'\n",
    "class_names = os.listdir(data_dir) # ['Finished', 'Opened', 'Sealed']\n",
    "\n",
    "print(\"‚úÖ Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ed850f",
   "metadata": {},
   "source": [
    "### ‚öñÔ∏è Check Class Balance\n",
    "**Displays the number of images per class and their percentage.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c4908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dataset_balance():\n",
    "    counts = {}\n",
    "    for class_dir in sorted(class_names): \n",
    "        class_path = os.path.join(data_dir, class_dir)\n",
    "        if os.path.isdir(class_path):\n",
    "            counts[class_dir] = len([f for f in os.listdir(class_path) \n",
    "                                   if f.lower().endswith(('.jpg', '.png', '.jpeg'))])\n",
    "    \n",
    "    total = sum(counts.values())\n",
    "    print(\"Dataset Balance:\")\n",
    "    print(counts)\n",
    "    print(\"Ratios:\", {k: f\"{v/total*100:.1f}%\" for k,v in counts.items()})\n",
    "\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, len(class_names)))\n",
    "    bars = plt.bar(class_names, counts.values(), color=colors)\n",
    "    plt.bar_label(bars, padding=-30) \n",
    "    plt.ylabel('Image Count')\n",
    "    plt.title('Dataset Class Balance')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "check_dataset_balance()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3b934b",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "**Trains the model then saves it as a .keras model file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf05e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns 3 shuffled data frames of the 80/10/10 data split\n",
    "def build_df_splits(data_dir):\n",
    "    seed = 42 # seed only controls the df splits\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    files = []\n",
    "    labels = []\n",
    "\n",
    "    valid_ext = (\".jpg\", \".jpeg\", \".png\")\n",
    "\n",
    "    for cls in class_names:\n",
    "        cls_dir = os.path.join(data_dir, cls)\n",
    "        if not os.path.isdir(cls_dir):\n",
    "            continue\n",
    "\n",
    "        for f in os.listdir(cls_dir):\n",
    "            if f.lower().endswith(valid_ext):\n",
    "                files.append(os.path.join(cls_dir, f)) # gets all filepaths of images\n",
    "                labels.append(cls) # gets all labels/class names of images\n",
    "\n",
    "    df = pd.DataFrame({\"filename\": files, \"class\": labels})\n",
    "    df = df.sample(frac=1, random_state=seed).reset_index(drop=True) # randomises its order\n",
    "\n",
    "    n = len(df) # total number of images\n",
    "    train_end = int(0.8 * n)\n",
    "    val_end = int(0.9 * n)\n",
    "\n",
    "    train_df = df[:train_end] # 80% goes to training dataframe\n",
    "    val_df   = df[train_end:val_end] # 10% goes to training dataframe\n",
    "    test_df  = df[val_end:] # 10% goes to training dataframe\n",
    "\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "# returns the 3 respective image generators\n",
    "def build_image_generators():\n",
    "    img_size = HYPER_PARAMS[\"IMG_SIZE\"]\n",
    "    batch_size = HYPER_PARAMS[\"BATCH_SIZE\"]\n",
    "    train_df, val_df, test_df = build_df_splits(data_dir)\n",
    "\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255, # normalizes pixel values\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True # 5 methods of data augmentation\n",
    "    )\n",
    "    val_test_datagen = ImageDataGenerator(rescale=1./255) # only normalize pixel values, no data aug\n",
    "\n",
    "    train_gen = train_datagen.flow_from_dataframe(\n",
    "        train_df,\n",
    "        x_col=\"filename\",\n",
    "        y_col=\"class\",\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    val_gen = val_test_datagen.flow_from_dataframe(\n",
    "        val_df,\n",
    "        x_col=\"filename\",\n",
    "        y_col=\"class\",\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    test_gen = val_test_datagen.flow_from_dataframe(\n",
    "        test_df,\n",
    "        x_col=\"filename\",\n",
    "        y_col=\"class\",\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return train_gen, val_gen, test_gen\n",
    "\n",
    "def build_model():\n",
    "    base_model = InceptionV3(input_shape=(*HYPER_PARAMS[\"IMG_SIZE\"], 3), include_top=False, weights='imagenet')\n",
    "    base_model.trainable = False\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(256)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    predictions = Dense(len(class_names), activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "# Start of program flow\n",
    "\n",
    "# 1. Generates ImageGens for each class in dataset\n",
    "print(\"\\nüìä Loading data...\")\n",
    "train_gen, val_gen, test_gen = build_image_generators()\n",
    "\n",
    "# 2. Alleviates uneven class image counts\n",
    "print(\"\\n‚öñÔ∏è Balancing class weights...\")\n",
    "class_weights = compute_class_weight(\n",
    "    'balanced', classes=np.unique(train_gen.classes), y=train_gen.classes\n",
    ")\n",
    "class_indices = train_gen.class_indices\n",
    "class_weight_dict = {class_indices[class_name]: weight \n",
    "                     for class_name, weight in zip(class_indices.keys(), class_weights)}\n",
    "\n",
    "# 3. Build the model's layers\n",
    "print(\"\\nüî® Building model...\") \n",
    "model = build_model()\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# 4. Training the model\n",
    "print(\"\\nüöÄ Training...\")\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=3, restore_best_weights=True, monitor='val_accuracy'), # patience means wait x epochs before doing smth\n",
    "    ReduceLROnPlateau(factor=0.2, patience=2, min_lr=1e-7) # slows learning rate to prevent it from bouncing\n",
    "]\n",
    "start_time = time.time()\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    epochs=HYPER_PARAMS['EPOCHS'],\n",
    "    validation_data=val_gen,\n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1 # prints the cool progress bar\n",
    ")\n",
    "training_time = time.time() - start_time\n",
    "model_accuracy = model.evaluate(test_gen)[1]\n",
    "\n",
    "# 5. Simple post-training metrics\n",
    "print(f\"‚åõ Total training time: ({training_time/60:.2f} minutes)\")\n",
    "print(\"\\n‚úÖ Test accuracy:\", model_accuracy)\n",
    "\n",
    "# 6. Save the model as a .keras file with accuracy & timestamp\n",
    "timestamp = datetime.datetime.now().strftime(\"%b%d_%H%M\")\n",
    "filename = f\"{int(model_accuracy * 100)}acc_model_{timestamp}.keras\"\n",
    "model.save(f'./models/{filename}')\n",
    "print(f\"üíæ Saved: {filename}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45cf29c",
   "metadata": {},
   "source": [
    "## ======================================\n",
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434e4eeb",
   "metadata": {},
   "source": [
    "- Data Visualization (using Matplotlib for graphs such as loss vs. epochs, accuracy vs. epochs) 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f67bf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hi\") # work in progress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cb305a",
   "metadata": {},
   "source": [
    "## ======================================\n",
    "# Trying the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63f7e9e",
   "metadata": {},
   "source": [
    "### üîÉ Load a .keras model\n",
    "Loading a model is necessary if the above code to train a new model was not executed.\n",
    "(Skip this if model was recently trained above)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079a01eb",
   "metadata": {},
   "source": [
    "üî¥ Option A - Load the latest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8dfae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"./models/\"\n",
    "files = [f for f in os.listdir(folder) if f.endswith('.keras')]\n",
    "if not files: raise FileNotFoundError(\"‚ùå No models found!\")\n",
    "latest_model = max(files, key=lambda f: os.path.getmtime(os.path.join(folder, f)))\n",
    "model = tf.keras.models.load_model(os.path.join(folder, latest_model))\n",
    "print(\"‚úÖ Loaded Latest Model:\", latest_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f89a33",
   "metadata": {},
   "source": [
    "üîµ Option B - Load other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aa04e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"./models/\"\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "model_paths = filedialog.askopenfilenames(\n",
    "    title=\"Select model file (.keras)\",\n",
    "    initialdir=folder,\n",
    "    filetypes=[(\"Keras models\", \"*.keras\")]\n",
    ")\n",
    "root.destroy()\n",
    "if not model_paths:\n",
    "    raise FileNotFoundError(\"‚ùå No model selected.\")\n",
    "full_path = model_paths[0]\n",
    "model_filename = os.path.basename(full_path)\n",
    "model = tf.keras.models.load_model(full_path)\n",
    "print(\"‚úÖ Loaded Model:\", model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c72f5ac",
   "metadata": {},
   "source": [
    "### Method 1: Inference using Camera Stream üì∑ \n",
    "(Please view the cell under this one to terminate the camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a6ca96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_and_predict(image_data):\n",
    "    image = ImageOps.fit(image_data, HYPER_PARAMS['IMG_SIZE'], Image.Resampling.LANCZOS)\n",
    "    image = image.convert('RGB')\n",
    "    image = np.asarray(image)\n",
    "    image = (image.astype(np.float32) / 255.0)\n",
    "    img_reshape = image[np.newaxis,...]\n",
    "    prediction = model.predict(img_reshape, verbose=0)\n",
    "    return prediction\n",
    "\n",
    "stop_flag = False\n",
    "\n",
    "def camera_loop():\n",
    "    global stop_flag\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        cap.open()\n",
    "        \n",
    "    print(\"Camera Started!\")\n",
    "\n",
    "    while not stop_flag:\n",
    "        ret, original = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        image = Image.fromarray(cv2.cvtColor(original, cv2.COLOR_BGR2RGB))\n",
    "        prediction = import_and_predict(image)\n",
    "\n",
    "        idx = np.argmax(prediction)\n",
    "        confidence = prediction[0][idx] \n",
    "\n",
    "        predict = f\"It is {class_names[idx]}! ({confidence:.2f})\"\n",
    "\n",
    "        cv2.putText(original, predict, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "        cv2.imshow(\"Cup Noodles Detector\", original)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            stop_flag = True\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# start the camera in a separate thread\n",
    "camera_thread = threading.Thread(target=camera_loop)\n",
    "camera_thread.start()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0569d8e4",
   "metadata": {},
   "source": [
    "‚ùå Run to terminate the camera! üëá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c4efcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_flag = True\n",
    "camera_thread.join()\n",
    "print(\"Killed the Camera!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8e420f",
   "metadata": {},
   "source": [
    "### Method 2: Inference using Image File Upload üñºÔ∏è "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9d2490",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "\n",
    "COLUMNS = 5\n",
    "\n",
    "def select_images_with_tkinter():\n",
    "    \"\"\"\n",
    "    Opens tkinter file dialog to select multiple image files.\n",
    "    Returns list of full file paths.\n",
    "    \"\"\"\n",
    "    root = tk.Tk()\n",
    "    root.withdraw() \n",
    "    root.attributes('-topmost', True)\n",
    "    \n",
    "    # Open file dialog for multiple images\n",
    "    file_paths = filedialog.askopenfilenames(\n",
    "        title=\"Select images to predict\",\n",
    "        filetypes=[\n",
    "            (\"Image files\", \"*.jpg *.jpeg *.png *.bmp *.tiff *.gif\"),\n",
    "            (\"All files\", \"*.*\")\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    root.destroy()\n",
    "    return list(file_paths)\n",
    "\n",
    "def visualize_predictions_from_files(image_paths: list, class_names: list[str]) -> None:\n",
    "    \"\"\"\n",
    "    Visualize predictions from a list of image file paths (from tkinter).\n",
    "    \"\"\"\n",
    "    if not image_paths:\n",
    "        print(\"No images selected.\")\n",
    "        return\n",
    "    \n",
    "    rows = math.ceil(len(image_paths) / COLUMNS)\n",
    "    plt.figure(figsize=(COLUMNS * 4, rows * 4))\n",
    "    \n",
    "    for i, img_path in enumerate(image_paths):\n",
    "        # Load image\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"‚ö†Ô∏è Could not load {img_path}\")\n",
    "            continue\n",
    "            \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Preprocess\n",
    "        img_resized = cv2.resize(img, (224, 224))\n",
    "        img_norm = img_resized / 255.0\n",
    "        img_input = np.expand_dims(img_norm, axis=0)\n",
    "        \n",
    "        # Predict\n",
    "        preds = model.predict(img_input, verbose=0)\n",
    "        class_id = np.argmax(preds[0])\n",
    "        confidence = preds[0][class_id]\n",
    "        filename = os.path.basename(img_path)  # Just filename for title\n",
    "        label = f\"{class_names[class_id]} ({confidence:.2f})\"\n",
    "        \n",
    "        # Plot\n",
    "        plt.subplot(rows, COLUMNS, i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"{filename[:20]}...\\n{label}\", fontsize=10)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Usage - replaces the old line\n",
    "class_names = ['Finished', 'Opened', 'Sealed']\n",
    "image_files = select_images_with_tkinter()\n",
    "visualize_predictions_from_files(image_files, class_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
